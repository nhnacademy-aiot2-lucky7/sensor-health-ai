import pandas as pd
import pickle
import os
import logging
from datetime import datetime, timedelta, timezone
from config import settings
from heuristic_health_score import heuristic_health_score
from services.analysis_result_service import send_analysis_result


REQUIRED_DAYS = 15
KST = timezone(timedelta(hours=9))

logger = logging.getLogger(__name__)

def load_model(sensor_type: str, gateway_id: str, sensor_id: str):
    model_path = f"model_registry/{sensor_type}/{gateway_id}_{sensor_id}.pkl"
    if not os.path.isfile(model_path):
        return None
    try:
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        return model
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def save_model(model, sensor_type, gateway_id, sensor_id):
    model_dir = f"model_registry/{sensor_type}"
    os.makedirs(model_dir, exist_ok=True)
    model_path = f"{model_dir}/{gateway_id}_{sensor_id}.pkl"
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    logger.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

def predict(sensor_type: str, gateway_id: str, sensor_id: str, data: pd.DataFrame) -> dict:
    from model_trainer import train_model  # ğŸ”„ ì¡°ê±´ ë§Œì¡± ì‹œ ë‚´ë¶€ì—ì„œ í˜¸ì¶œ

    actual_days = len(data)
    analyzed_at = int(datetime.now(KST).timestamp())

    if actual_days < REQUIRED_DAYS:
        logger.info(f"ë°ì´í„° ì¼ìˆ˜ ë¶€ì¡±: {actual_days} < {REQUIRED_DAYS}")
        return {
            "result": {
                "analysisType": "THRESHOLD_DIFF_ANALYSIS",
                "sensorInfo": {
                    "gatewayId": gateway_id,
                    "sensorId": sensor_id,
                    "sensorType": sensor_type
                },
                "model": None,
                "healthScore": None,
                "analyzedAt": analyzed_at,
                "meta": {
                    "analysisStatus": "insufficient_data",
                    "failureReason": "not_enough_days",
                    "actualDataDays": actual_days,
                    "requiredData_days": REQUIRED_DAYS,
                    "analysisWindowDays": REQUIRED_DAYS
                }
            }
        }

    required_columns = ['min_diff', 'max_diff', 'avg_diff']
    if not all(col in data.columns for col in required_columns):
        logger.error(f"í•„ìš” ì»¬ëŸ¼ ëˆ„ë½: {required_columns} ì¤‘ ì¼ë¶€ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        return {
            "result": {
                "analysisType": "THRESHOLD_DIFF_ANALYSIS",
                "sensorInfo": {
                    "gatewayId": gateway_id,
                    "sensorId": sensor_id,
                    "sensorType": sensor_type
                },
                "model": None,
                "healthScore": None,
                "analyzedAt": analyzed_at,
                "meta": {
                    "analysisStatus": "invalid_data",
                    "failureReason": "missing_required_columns",
                    "actualDataDays": actual_days,
                    "requiredData_days": REQUIRED_DAYS,
                    "analysisWindowDays": REQUIRED_DAYS
                }
            }
        }

    if data[required_columns].isnull().values.any():
        logger.error("ê²°ì¸¡ì¹˜ ì¡´ì¬: ë°ì´í„°ì— NULL ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {
            "result": {
                "analysisType": "THRESHOLD_DIFF_ANALYSIS",
                "sensorInfo": {
                    "gatewayId": gateway_id,
                    "sensorId": sensor_id,
                    "sensorType": sensor_type
                },
                "model": None,
                "healthScore": None,
                "analyzedAt": analyzed_at,
                "meta": {
                    "analysisStatus": "invalid_data",
                    "failureReason": "contains_null_values",
                    "actualDataDays": actual_days,
                    "requiredData_days": REQUIRED_DAYS,
                    "analysisWindowDays": REQUIRED_DAYS
                }
            }
        }

    model = load_model(sensor_type, gateway_id, sensor_id)
    x_input = data[required_columns].mean().values.reshape(1, -1)

    if model:
        score = model.predict(x_input)[0]
        model_type = "RandomForest"
        logger.info(f"ëª¨ë¸ ì˜ˆì¸¡ ì„±ê³µ - ì ìˆ˜: {score}")
    else:
        # âœ¨ ì¡°ê±´ ë§Œì¡± ì‹œ í•™ìŠµ ì‹œë„
        if 'health_score' in data.columns and actual_days >= REQUIRED_DAYS:
            try:
                logger.info(f"ëª¨ë¸ì´ ì—†ì–´ í•™ìŠµ ì‹œë„ ì¤‘: {sensor_type}/{gateway_id}/{sensor_id}")
                model = train_model(data)
                save_model(model, sensor_type, gateway_id, sensor_id)
                score = model.predict(x_input)[0]
                model_type = "RandomForest (newly trained)"
                logger.info(f"ìƒˆ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì„±ê³µ - ì ìˆ˜: {score}")
            except Exception as e:
                logger.error(f"ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨, íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ëŒ€ì²´: {e}")
                score = heuristic_health_score(data)
                model_type = "Heuristic-based (fallback)"
        else:
            score = heuristic_health_score(data)
            model_type = "Heuristic-based"
            logger.info("ëª¨ë¸ì´ ì—†ì–´ heuristicìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°")

    return {
        "result": {
            "analysisType": "THRESHOLD_DIFF_ANALYSIS",
            "sensorInfo": {
                "gatewayId": gateway_id,
                "sensorId": sensor_id,
                "sensorType": sensor_type
            },
            "model": model_type,
            "healthScore": round(score, 4),
            "analyzedAt": analyzed_at,
            "meta": {
                "analysisStatus": "analyzed",
                "failureReason": None,
                "actualDataDays": actual_days,
                "requiredData_days": REQUIRED_DAYS,
                "analysisWindowDays": REQUIRED_DAYS
            }
        }
    }

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 6:
        logger.error("ì‚¬ìš©ë²•: python health_predictor.py <csv_path> <sensor_type> <gateway_id> <sensor_id> <output_json_path>")
        sys.exit(1)

    csv_path, sensor_type, gateway_id, sensor_id, output_path = sys.argv[1:]

    try:
        df = pd.read_csv(csv_path, parse_dates=['date'])
        df_filtered = df[(df['gateway_id'] == gateway_id) & (df['sensor_id'] == sensor_id)]
        df_filtered = df_filtered.sort_values(by='date').tail(REQUIRED_DAYS)

        result = predict(sensor_type, gateway_id, sensor_id, df_filtered)

        send_analysis_result(result)
        logger.info("ì˜ˆì¸¡ ê²°ê³¼ ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        sys.exit(1)
