import os
import pandas as pd
from datetime import datetime
from services.sensor_service import fetch_threshold_history, save_by_sensor_and_type, DATA_DIR
from models.health_predictor import predict
from services.analysis_result_service import send_analysis_result

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def run_pipeline():
    # 1. ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘
    logger.info("ğŸ“¡ ì„¼ì„œ ì„ê³„ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    df = fetch_threshold_history(datetime.now())
    
    if df.empty:
        logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ")
        return

    # 2. ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì„¼ì„œíƒ€ì…ë³„ CSVë¡œ ì €ì¥
    logger.info("ğŸ’¾ ì„¼ì„œ íƒ€ì…ë³„ CSV ì €ì¥")
    save_by_sensor_and_type(df)

    # 3. CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ ì„¼ì„œë³„ë¡œ health_predictor í˜¸ì¶œ
    for sensor_type_file in os.listdir(DATA_DIR):
        if not sensor_type_file.endswith(".csv"):
            continue

        sensor_type = sensor_type_file.replace(".csv", "")
        file_path = os.path.join(DATA_DIR, sensor_type_file)
        try:
            df = pd.read_csv(file_path, parse_dates=["date"])
        except Exception as e:
            logger.error(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {file_path} - {e}")
            continue

        # 4. ì„¼ì„œ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        for (gateway_id, sensor_id), group_df in df.groupby(["gateway_id", "sensor_id"]):
            df_sensor = group_df.sort_values(by="date").tail(15)
            try:
                result = predict(sensor_type, gateway_id, sensor_id, df_sensor)
                send_analysis_result(result)
                logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ ë° ì „ì†¡: {sensor_type}/{gateway_id}/{sensor_id}")
            except Exception as e:
                logger.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {sensor_type}/{gateway_id}/{sensor_id} - {e}")

if __name__ == "__main__":
    run_pipeline()
